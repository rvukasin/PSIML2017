{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop LR Petnica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important functions:\n",
    "### Sigmoid function:\n",
    "\n",
    "\\begin{equation*}\n",
    "S(x) = \\frac{1}{1 + e^{-x}}\n",
    "\\end{equation*}\n",
    "\n",
    "You can find more at *https://en.wikipedia.org/wiki/Sigmoid_function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    #Fill in sigmoid computation\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usage example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sigmoid(0))\n",
    "testArray = np.array([1,5])\n",
    "print(sigmoid(testArray))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ploting sigmoid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.arange(-10., 10., 0.2)\n",
    "y = sigmoid(x)\n",
    "plt.plot(x,y)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLu function:\n",
    "\n",
    "\\begin{equation*}\n",
    "f(x)  = \\begin{cases}\n",
    "    x & \\mbox{if } x > 0 \\\\\n",
    "    0 & \\mbox{otherwise}\n",
    "\\end{cases}\n",
    "\\end{equation*}\n",
    "\n",
    "You can find more at *https://en.wikipedia.org/wiki/Rectifier_(neural_networks)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    # Fill in ReLu funcion\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(relu(-5))\n",
    "print(relu(5))\n",
    "testArray = np.array([3,0,-1,2,5,-2])\n",
    "print(relu(testArray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = np.arange(-10., 10., 0.2)\n",
    "rel = relu(x)\n",
    "plt.plot(x,rel)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax:\n",
    "\n",
    "\\begin{equation*}\n",
    "P(y=i\\mid \\mathbf{x}) = \\frac{e^{\\mathbf{x}_i}}{\\sum_{k=1}^K e^{\\mathbf{x}_k}}\n",
    "\\end{equation*}\n",
    "\n",
    "You can find more at *https://en.wikipedia.org/wiki/Softmax_function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    # Fill in softmax function\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testArray = np.array([-1,0.1899,0.4449,0.98990])\n",
    "print(softmax(testArray))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression\n",
    "\n",
    "### Hypothesis:\n",
    "\n",
    "\\begin{equation*}\n",
    "h(x) = \\frac {1}{1+e^{-\\sum_{i=0}^K{w_i x_i}}}\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hypothesis(features, weights):\n",
    "    # Fill in hypothesis\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array([1,2])\n",
    "weights = np.array([0.05,0.2])\n",
    "\n",
    "print(hypothesis(features, weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost function:\n",
    "\n",
    "\\begin{equation*}\n",
    "J = \\frac {1} {n} \\sum_{i=i}^n{cost(h(X_i),Y_i)} \n",
    "\\end{equation*}\n",
    "\\begin{equation*}\n",
    "J = \\frac {1} {n} \\sum_{i=i}^n{[-ylog(h(x)) - (1-y)log(1 -h(x))]} \n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cost_function(features, weights, target):\n",
    "    # Fill in cost function\n",
    "    cost = 0\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and reading model from file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_params(file_path, weights):\n",
    "    np.savez(file_path, weights=weights)\n",
    "\n",
    "def load_params(file_path):\n",
    "    data = np.load(file_path)\n",
    "    return data['weights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.array([0.05,0.2])\n",
    "save_params(\"testmodel.tsv\", weights)\n",
    "data = load_params(\"testmodel.tsv.npz\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_results(targets, predictions):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    # Calculate tp, fp, fn, tn, p and r\n",
    "    \n",
    "    return TP, FP, TN, FN, P, R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_model(weights, x):\n",
    "    # For a given weights and data, calculate metrics\n",
    "    print(\"True positive count: \" + str(TP))\n",
    "    print(\"False positive count: \" + str(FP))\n",
    "    print(\"True negative count: \" + str(TN))\n",
    "    print(\"False negative count: \" + str(FN))\n",
    "    print(\"Precision: \" + str(P))\n",
    "    print(\"Recall: \" + str(R))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model, datasets\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "y = (y == 1).astype(int).T\n",
    "bias = np.zeros((x.shape[0],1)) + 1\n",
    "x = np.append(bias, x, axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = .02  # step size in the mesh\n",
    "\n",
    "LR = linear_model.LogisticRegression(C=1e5)\n",
    "\n",
    "LR.fit(x, y)\n",
    "\n",
    "predictions = LR.predict(x)\n",
    "\n",
    "TP, FP, TN, FN, P, R = train_results(y, predictions)\n",
    "print(\"True positive count: \" + str(TP))\n",
    "print(\"False positive count: \" + str(FP))\n",
    "print(\"True negative count: \" + str(TN))\n",
    "print(\"False negative count: \" + str(FN))\n",
    "print(\"Precision: \" + str(P))\n",
    "print(\"Recall: \" + str(R))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algorithm:\n",
    "\n",
    "##### Gradient descent:\n",
    "\n",
    "\\begin{equation*}\n",
    "w_i = w_i - \\alpha \\sum_{j=1}^n {(h(X^{(j)}) - y^{(j)}) x_i^{(j)}}\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic_regression(features, target, epochCount, learning_rate):\n",
    "    n = features.shape[0]\n",
    "    weights = np.zeros(features.shape[1])\n",
    "    \n",
    "    for step in range(epochCount):\n",
    "        # Fill in algorithm\n",
    "        \n",
    "        # Save cost function value every so often\n",
    "        if step % 100 == 0:\n",
    "            costData.append(cost_function(features, weights, target))\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "costData = []\n",
    "epochCount = 10000\n",
    "weights = logistic_regression(x, y, epochCount = epochCount, learning_rate = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x[80])\n",
    "print(y[80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sigmoid(weights[0] + weights[1] * 5.5 + weights[2] * 2.4 + weights[3] * 3.8 + weights[4] * 1.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot cost function over epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(0., epochCount/100, 1.)\n",
    "plt.plot(a,costData)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_model(weights, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Regularization:\n",
    "\n",
    "\n",
    "#### Regularization cost: \n",
    "\\begin{equation*}\n",
    "J = \\frac {1} {n} \\sum_{i=1}^n{cost(h(X_i),Y_i)} + \\frac {μ}{2n}\\sum_{i=1}^m{w_i^2}\n",
    "\\end{equation*}\n",
    "\\begin{equation*}\n",
    "J = \\frac {1} {n} \\sum_{i=1}^n{[-y log(h(x)) - (1-y) log(1 - h(x))]} + \\frac {μ}{2n}\\sum_{i=1}^m{w_i^2}\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cost_function_reg(features, weights, target, regularization):\n",
    "    # Fill in cost function that uses regularization\n",
    "    m = len(weights)\n",
    "    cost = 0\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient: \n",
    "\n",
    "\\begin{equation*}\n",
    "w_0 = w_0 - \\alpha [\\frac{1}{n} \\sum_{j=1}^n {(h(X^{(j)}) - y^{(j)}) x_i^{(j)}}]\n",
    "\\end{equation*}\n",
    "\\begin{equation*}\n",
    "w_i = w_i - \\alpha [\\frac{1}{n} \\big\\langle\\sum_{j=1}^n {(h(X^{(j)}) - y^{(j)}) x_i^{(j)}}\\big\\rangle + \\frac {μ}{n}w_i]\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic_regression_reg(features, target, epochCount, learning_rate, regularization):\n",
    "    n = features.shape[0]\n",
    "    weights = np.zeros(features.shape[1])\n",
    "    \n",
    "    for step in range(epochCount):\n",
    "        # Fill in algorithm\n",
    "            \n",
    "        # Save cost function value every so often\n",
    "        if step % 100 == 0:\n",
    "            costData.append(cost_function(features, weights, target))\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costData = []\n",
    "epochCount = 10000\n",
    "weights = logistic_regression_reg(x, y, epochCount = epochCount, learning_rate = 0.1, regularization = 0.1)\n",
    "print(weights)\n",
    "a = np.arange(0., epochCount/100, 1.)\n",
    "plt.plot(a,costData)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_model(weights, x)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
